{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 语病检测 - 科大讯飞\n",
    "\n",
    "Author: Zexin Xu, Zilu Zhang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理\n",
    "For this dataset only. Do not run this for other datasets.\n",
    "\n",
    "* `tunit_df` includes tunits data\n",
    "* `sen_df` includes sentences data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('mysen_edit.xlsx')  # read excel file\n",
    "df.drop(['say'], axis=1, inplace=True)  # drop column\n",
    "df.dropna(subset=['sentences', 'correct_final'], inplace=True) # drop empty rows\n",
    "df = df.reset_index(drop=True)\n",
    "df['sentences'] = df['sentences'].str.replace(r'_x000D_\\n', '', regex=True)  # remove _x000D_\\n\n",
    "df['sentences'] = df['sentences'].str.replace(r'\\n', '', regex=True)  # remove \\n\n",
    "df.head()\n",
    "\n",
    "#NOTE Check if there is any empty cell in 'correct' or 'sen'\n",
    "# df['correct'].isnull().values.any()\n",
    "# df['sen'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunit_df = pd.DataFrame({\n",
    "    'sentence': df['sentences'], \n",
    "    'ground_truth_label': df['correct_final']\n",
    "})\n",
    "tunit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"\"\n",
    "correct = True\n",
    "sent_arr = []\n",
    "correct_arr = []\n",
    "for i, row in df.iterrows():\n",
    "    sent += row['sentences']\n",
    "    correct = correct and row['correct_final']\n",
    "    if row['sen'] == 0:\n",
    "        sent += \"，\"\n",
    "    else:\n",
    "        sent += \"。\"\n",
    "        sent.replace(\"_x000D_\\n\", \"\")\n",
    "        sent_arr.append(sent)\n",
    "        correct_arr.append(correct)\n",
    "        # reset\n",
    "        sent = \"\"\n",
    "        correct = True\n",
    "        \n",
    "sen_df = pd.DataFrame({\n",
    "    'sentence': sent_arr, \n",
    "    'ground_truth_label': correct_arr\n",
    "})\n",
    "sen_df.head()   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 科大讯飞API调用\n",
    "\n",
    "* Credit: https://www.xfyun.cn/doc/nlp/textCorrection/API.html#%E8%BF%94%E5%9B%9E%E7%BB%93%E6%9E%9C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "from datetime import datetime\n",
    "from wsgiref.handlers import format_date_time\n",
    "from time import mktime\n",
    "import hashlib\n",
    "import base64\n",
    "import hmac\n",
    "from urllib.parse import urlencode\n",
    "import json\n",
    "import requests\n",
    "\n",
    "\n",
    "class AssembleHeaderException(Exception):\n",
    "    def __init__(self, msg):\n",
    "        self.message = msg\n",
    "\n",
    "\n",
    "class Url:\n",
    "    def __init__(this, host, path, schema):\n",
    "        this.host = host\n",
    "        this.path = path\n",
    "        this.schema = schema\n",
    "        pass\n",
    "\n",
    "\n",
    "class WebsocketDemo:\n",
    "    def __init__(self,APPId,APISecret,APIKey,Text):\n",
    "        self.appid = APPId\n",
    "        self.apisecret = APISecret\n",
    "        self.apikey = APIKey\n",
    "        self.text = Text\n",
    "        self.url = 'https://api.xf-yun.com/v1/private/s9a87e3ec'\n",
    "\n",
    "    # calculate sha256 and encode to base64\n",
    "    def sha256base64(self,data):\n",
    "        sha256 = hashlib.sha256()\n",
    "        sha256.update(data)\n",
    "        digest = base64.b64encode(sha256.digest()).decode(encoding='utf-8')\n",
    "        return digest\n",
    "\n",
    "\n",
    "    def parse_url(self,requset_url):\n",
    "        stidx = requset_url.index(\"://\")\n",
    "        host = requset_url[stidx + 3:]\n",
    "        schema = requset_url[:stidx + 3]\n",
    "        edidx = host.index(\"/\")\n",
    "        if edidx <= 0:\n",
    "            raise AssembleHeaderException(\"invalid request url:\" + requset_url)\n",
    "        path = host[edidx:]\n",
    "        host = host[:edidx]\n",
    "        u = Url(host, path, schema)\n",
    "        return u\n",
    "\n",
    "\n",
    "    # build websocket auth request url\n",
    "    def assemble_ws_auth_url(self,requset_url, method=\"POST\", api_key=\"\", api_secret=\"\"):\n",
    "        u = self.parse_url(requset_url)\n",
    "        host = u.host\n",
    "        path = u.path\n",
    "        now = datetime.now()\n",
    "        date = format_date_time(mktime(now.timetuple()))\n",
    "        #print(date)\n",
    "        # date = \"Thu, 12 Dec 2019 01:57:27 GMT\"\n",
    "        signature_origin = \"host: {}\\ndate: {}\\n{} {} HTTP/1.1\".format(host, date, method, path)\n",
    "        #print(signature_origin)\n",
    "        signature_sha = hmac.new(api_secret.encode('utf-8'), signature_origin.encode('utf-8'),\n",
    "                                 digestmod=hashlib.sha256).digest()\n",
    "        signature_sha = base64.b64encode(signature_sha).decode(encoding='utf-8')\n",
    "        authorization_origin = \"api_key=\\\"%s\\\", algorithm=\\\"%s\\\", headers=\\\"%s\\\", signature=\\\"%s\\\"\" % (\n",
    "            api_key, \"hmac-sha256\", \"host date request-line\", signature_sha)\n",
    "        authorization = base64.b64encode(authorization_origin.encode('utf-8')).decode(encoding='utf-8')\n",
    "        #print(authorization_origin)\n",
    "        values = {\n",
    "            \"host\": host,\n",
    "            \"date\": date,\n",
    "            \"authorization\": authorization\n",
    "        }\n",
    "\n",
    "        return requset_url + \"?\" + urlencode(values)\n",
    "\n",
    "\n",
    "    def get_body(self):\n",
    "        body =  {\n",
    "            \"header\": {\n",
    "                \"app_id\": self.appid,\n",
    "                \"status\": 3,\n",
    "                #\"uid\":\"your_uid\"\n",
    "            },\n",
    "            \"parameter\": {\n",
    "                \"s9a87e3ec\": {\n",
    "                    #\"res_id\":\"your_res_id\",\n",
    "                    \"result\": {\n",
    "                        \"encoding\": \"utf8\",\n",
    "                        \"compress\": \"raw\",\n",
    "                        \"format\": \"json\"\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"payload\": {\n",
    "                \"input\": {\n",
    "                    \"encoding\": \"utf8\",\n",
    "                    \"compress\": \"raw\",\n",
    "                    \"format\": \"plain\",\n",
    "                    \"status\": 3,\n",
    "                    \"text\": base64.b64encode(self.text.encode(\"utf-8\")).decode('utf-8')\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        return body\n",
    "\n",
    "    def get_result(self):\n",
    "        request_url = self.assemble_ws_auth_url(self.url, \"POST\", self.apikey, self.apisecret)\n",
    "        headers = {'content-type': \"application/json\", 'host':'api.xf-yun.com', 'app_id':self.appid}\n",
    "        body = self.get_body()\n",
    "        response = requests.post(request_url, data = json.dumps(body), headers = headers)\n",
    "        # print('onMessage：\\n' + response.content.decode())\n",
    "        tempResult = json.loads(response.content.decode())\n",
    "        # print('text字段解析：\\n' + base64.b64decode(tempResult['payload']['result']['text']).decode())\n",
    "        return json.loads(base64.b64decode(tempResult['payload']['result']['text']).decode())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(result):\n",
    "    if len(result) > 0:\n",
    "        print(str(result))\n",
    "        return str(result)\n",
    "    else:\n",
    "        return pd.NA\n",
    "    \n",
    "def generate_result(df):\n",
    "    APPId = \"\"\n",
    "    APISecret = \"\"\n",
    "    APIKey = \"\"\n",
    "\n",
    "    for i, row in df.loc[:, :].iterrows():\n",
    "        demo = WebsocketDemo(APPId, APISecret, APIKey, row['sentences'])\n",
    "        result = demo.get_result()\n",
    "        df.loc[i, \"政治术语纠错\"] = get_result(result['pol']) \n",
    "        df.loc[i, \"别字纠错\"] = get_result(result['char']) \n",
    "        df.loc[i, \"别词纠错\"] = get_result(result['word'])\n",
    "        df.loc[i, \"语法纠错-冗余\"] = get_result(result['redund']) \n",
    "        df.loc[i, \"语法纠错-缺失\"] = get_result(result['miss']) \n",
    "        df.loc[i, \"语法纠错-乱序\"] = get_result(result['order']) \n",
    "        df.loc[i, \"搭配纠错\"] = get_result(result['dapei']) \n",
    "        df.loc[i, \"标点纠错\"] = get_result(result['punc']) \n",
    "        df.loc[i, \"成语纠错\"] = get_result(result['idm']) \n",
    "        df.loc[i, \"机构名纠错\"] = get_result(result['org']) \n",
    "        df.loc[i, \"领导人职称纠错\"] = get_result(result['leader']) \n",
    "        df.loc[i, \"数字纠错\"] = get_result(result['number']) \n",
    "        df.loc[i, \"地名纠错\"] = get_result(result['addr'])\n",
    "        df.loc[i, \"全文人名纠错\"] = get_result(result['name']) \n",
    "        df.loc[i, \"句式杂糅/语义重复\"] = get_result(result['grammar_pc']) \n",
    "        if i % 100 == 0:\n",
    "            print(i, \"iters done...\")\n",
    "\n",
    "kd_tunit_df = tunit_df.copy()\n",
    "generate_result(kd_tunit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kd_tunit_df = tunit_df.copy()\n",
    "generate_result(kd_tunit_df)\n",
    "kd_tunit_df.to_csv('kedaxunfei/tunit_df_result.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kd_sen_df = sen_df.copy()\n",
    "generate_result(kd_sen_df)\n",
    "kd_sen_df.to_csv('kedaxunfei/sen_df_result.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result processsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "kd_tunit_result = pd.read_csv('kedaxunfei/tunit_df_result.csv', encoding='utf-8')\n",
    "kd_sen_result = pd.read_csv('kedaxunfei/sen_df_result.csv', encoding='utf-8')\n",
    "\n",
    "def result_processing(df, tru_df):\n",
    "    df['纠错数'] = 15 - df.apply(lambda x: x.isnull().sum(), axis='columns')\n",
    "    for i, row in df.iterrows():\n",
    "        df.loc[i, 'prediction_label'] = False if row['纠错数'] > 0 else True\n",
    "    df['ground_truth_label'] = tru_df['ground_truth_label']\n",
    "    \n",
    "result_processing(kd_tunit_result, tunit_df)\n",
    "kd_tunit_result.to_csv('kedaxunfei/tunit_df_result_mod.csv', index=False, encoding='utf-8-sig')\n",
    "result_processing(kd_sen_result, sen_df)\n",
    "kd_sen_result.to_csv('kedaxunfei/sen_df_result_mod.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix 混淆矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_evaluation(golds, predictions):\n",
    "    \"\"\"\n",
    "    Prints evaluation statistics comparing golds and predictions, each of which is a sequence of 0/1 labels.\n",
    "    Prints accuracy as well as precision/recall/F1 of the positive class, which can sometimes be informative if either\n",
    "    the golds or predictions are highly biased.\n",
    "\n",
    "    :param golds: gold labels\n",
    "    :param predictions: pred labels\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    num_correct = 0\n",
    "    num_pos_correct = 0\n",
    "    num_pred = 0\n",
    "    num_gold = 0\n",
    "    num_total = 0\n",
    "    if len(golds) != len(predictions):\n",
    "        raise Exception(\"Mismatched gold/pred lengths: %i / %i\" % (len(golds), len(predictions)))\n",
    "    for idx in range(0, len(golds)):\n",
    "        gold = golds[idx]\n",
    "        prediction = predictions[idx]\n",
    "        if prediction == gold:\n",
    "            num_correct += 1\n",
    "        if prediction == 1:\n",
    "            num_pred += 1\n",
    "        if gold == 1:\n",
    "            num_gold += 1\n",
    "        if prediction == 1 and gold == 1:\n",
    "            num_pos_correct += 1\n",
    "        num_total += 1\n",
    "    acc = float(num_correct) / num_total\n",
    "    output_str = \"Accuracy: %i / %i = %f\" % (num_correct, num_total, acc)\n",
    "    prec = float(num_pos_correct) / num_pred if num_pred > 0 else 0.0\n",
    "    rec = float(num_pos_correct) / num_gold if num_gold > 0 else 0.0\n",
    "    f1 = 2 * prec * rec / (prec + rec) if prec > 0 and rec > 0 else 0.0\n",
    "    output_str += \";\\nPrecision (fraction of predicted positives that are correct): %i / %i = %f\" % (num_pos_correct, num_pred, prec)\n",
    "    output_str += \";\\nRecall (fraction of true positives predicted correctly): %i / %i = %f\" % (num_pos_correct, num_gold, rec)\n",
    "    output_str += \";\\nF1 (harmonic mean of precision and recall): %f;\\n\" % f1\n",
    "    return output_str\n",
    "\n",
    "kd_tunit_result = pd.read_csv('kedaxunfei/tunit_df_result_mod.csv', encoding='utf-8')\n",
    "kd_sen_result = pd.read_csv('kedaxunfei/sen_df_result_mod.csv', encoding='utf-8')\n",
    "print(\"------ Tunit Evaluation ------\")\n",
    "print(print_evaluation(kd_tunit_result['ground_truth_label'], kd_tunit_result['prediction_label']))\n",
    "print(\"------ Sentence Evaluation ------\")\n",
    "print(print_evaluation(kd_sen_result['ground_truth_label'], kd_sen_result['prediction_label']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "75273f6ed8af91899ebc591bf6ae2fd0716c5db2515d7097a000123632f4e53a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
